#!/usr/bin/env python3
import logging
import json
import os
import re
import requests
import sys
import unicodedata
import urllib.parse
from collections import OrderedDict
from pathlib import Path
from typing import Union
from xml.dom.minidom import parseString

logger = logging.basicConfig(level=logging.INFO)


def getText(nodelist):
    rc = []
    for node in nodelist:
        if node.nodeType == node.TEXT_NODE:
            rc.append(node.data)
    return ''.join(rc)


def getData(nodelist):
    rc = []
    for node in nodelist:
        if node.nodeType == node.DATA_NODE:
            rc.append(node.data)
    return ''.join(rc)


def oxford_command_join(elements):
    if len(elements) == 1:
        return elements[0]
    if len(elements) == 2:
        return ", ".join(elements)
    if len(elements) >= 3:
        elements[-1] = "and " + elements[-1]
        return ", ".join(elements)
    return ""

def slugify(value, allow_unicode=False):
    """
    Taken from https://github.com/django/django/blob/master/django/utils/text.py
    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated
    dashes to single dashes. Remove characters that aren't alphanumerics,
    underscores, or hyphens. Convert to lowercase. Also strip leading and
    trailing whitespace, dashes, and underscores.
    """
    value = str(value)
    if allow_unicode:
        value = unicodedata.normalize('NFKC', value).replace(u'\u2014','-')
    else:
        value = unicodedata.normalize('NFKD', value).replace(u'\u2014','-').encode('ascii', 'ignore').decode('ascii')
    value = re.sub(r'[^\w\s-]', '', value.lower())
    return re.sub(r'[-\s]+', '-', value).strip('-_')

def compute_duration_sec(duration_strings: list = []) -> int:
    total_sec = 0
    for ds in duration_strings:
        m, s = ds.split(":")
        sec = int(m)*60 + int(s)
        total_sec += sec
    return total_sec

def number_output_parts(parts_elements = []) -> int:
    durations = []
    for part in parts_elements:
        try:
            durations.append(part.getAttribute('duration'))
        except:
            part_num = part.getDuration('number')
            logging.warning(f"Part {part_num} has no duration attribute.  Total duration may be wrong.")
    sec = compute_duration_sec(durations)
    logging.debug(f"Run length is {sec} secnds long")
    max_sec_mp4 = 12 * 3600
    h,s = divmod(sec, 3600)
    m,s = divmod(s, 60)
    logging.debug(f'ODM reports run time at {h:02}:{m:02}:{s:02} (H:M:S)')
    return int(sec/max_sec_mp4) + 1

def orig_info_exists():
    p = Path('info.txt.orig')
    return p.exists()

def backup_info_text():
    os.rename('info.txt', 'info.txt.orig')

def import_info_txt() -> OrderedDict:
    p = Path('info.txt')
    info = OrderedDict()
    if p.exists() and p.is_file():
        with open(p.resolve(),"r") as f:
            logging.debug(f'Opened {p.resolve()} for importing')
            for line in f:
                try:
                    k, v = str.split(line,'=')
                    if not info.get(k.strip()) or (v.find("-Cover") >= 0 and k == "COVER"):
                        info[k.strip()] = v.strip()
                except:
                    pass
    return info

def hardback_year_google(author, title) -> Union[int, None]:
    base_url="https://www.googleapis.com/books/v1/volumes"
    params = {
        'maxResults': 40,
        'format': 'json',
        'printType': 'all',
        'q': f'"{author}" "{title}"'
    }

    headers = {}
    response = requests.get(base_url, headers=headers, params=params)
    logging.debug(f"GoogleAPI for books return {response.status_code}")
    if response.status_code < 400:
        c = response.content.decode(response.apparent_encoding)
        try:
            j = json.loads(c)
        except:
            raise ValueError("Error parsing json response from GoogleAPI")
    else:
        raise ValueError(f"GoogleAPI returned {response.status_code}, value {response.content}")
    set_author = set(author.lower().split(" "))
    set_title = set(title.lower().split(" "))
    published_date = None
    for entry in j['items']:
        vi = entry['volumeInfo']
        if not vi.get('title') or not vi.get('authors'):
            continue
        set_vi_title = set(vi['title'].lower().split(" "))
        set_vi_author = set(vi['authors'][0].lower().split(" "))
        if ( ( set_title.issubset(set_vi_title) or set_vi_title.issubset(set_title) ) and
           ( set_author.issubset(set_vi_author) or set_vi_author.issubset(set_author) ) ):
            published_date = vi['publishedDate']
            logging.debug(f"MATCH! title={vi['title']}. authors={vi['authors']}, year={vi['publishedDate']}")
            break
        else:
            logging.debug(f"title={vi['title']}. authors={vi['authors']}, year={vi['publishedDate']}")
    if not published_date:
        try:
            published_date = j['items'][0]['volumeInfo']['publishedDate']
            logging.warning(f"No good match in search results.  Using first guess: {published_date}")
        except:
            logging.warning("No search results, no year returned")
            return None

    match = re.search(r'((19|20)\d\d)',published_date)
    if match:
        logging.info(f"Extracted publication year {match.group(1)} from Google search results")
        return match.group(1)
    return None

fd = sys.stdin
if len(sys.argv) >= 2:
    logging.debug("Command line argument discovered")
    odm = sys.argv[1]
    logging.debug(f"Opening input file {odm}")
    if odm and Path(odm).is_file():
        fd = open(odm,"r")
    else:
        logging.warning(f"No such input file {odm}")
        exit(1)
else:
    logging.info("Reading ODM from stdin")

def main():
    logging.debug("Parsing XML")
    dom1 = parseString(str.join('', fd))
    logging.debug("Parsing complete.  Looking for OverDriveMedia tag")
    odm_dom = dom1.getElementsByTagName("OverDriveMedia")[0]
    logging.debug("Found.  Looking for CDATA with Metadata segment")
    # Shortcut for CDATA from https://stackoverflow.com/a/597111
    cdata = [n for n in odm_dom.childNodes if n.nodeType==odm_dom.CDATA_SECTION_NODE][0].data
    cdata = cdata.replace('& ', 'and ')
    cdata = cdata.replace('&#8212;', '—')
    cdata = cdata.replace(u'\u2014', '—')
    # one line search and replace - https://stackoverflow.com/a/50751493
    cdata = re.sub(r'&lt;/?\w+&gt;', '', cdata)
    logging.debug("Found.  Parsing Metadata in CDATA block")
    dom2 = parseString(cdata)
    logging.debug("Found.  Looking for additional elements.")
    authors = []
    narrators = []
    creators = dom2.getElementsByTagName('Creator')
    for c in creators:
        if c.getAttribute('role') == 'Author':
            authors.append(getText(c.childNodes))
        if c.getAttribute('role') == 'Narrator':
            narrators.append(getText(c.childNodes))
    title = getText(dom2.getElementsByTagName('Title')[0].childNodes)
    title = re.sub('[-;].*', '', title)
    try:
        series = getText(dom2.getElementsByTagName('Series')[0].childNodes)
        subtitle = getText(dom2.getElementsByTagName('SubTitle')[0].childNodes)
        series = re.sub(r'^(A|The)\s', '', series)
        book = 0
        m = re.search("book (\d+)", subtitle, re.IGNORECASE)
        if m:
            book = int(m.group(1))
    except:
        series = None
    description = getText(dom2.getElementsByTagName('Description')[0].childNodes) or ""
    parts_list = dom1.getElementsByTagName('Part')
    output_parts = number_output_parts(parts_list)
    part_text = ''
    lc_part_text = ''
    if output_parts > 1:
        part_text = ', Part ${PART}'  # not an f-string
        lc_part_text = '-part${PART}'  # not an f-string
        logging.warning(f"This book is more than 12 hours long. Use:   multipartEncode {output_parts}")

    properties = {
        'TITLE': f'{title}{part_text}',
        'ARTIST': f'{oxford_command_join(authors)}',
        'COMMENT': f'Read by {oxford_command_join(narrators)}'
    }

    #print(f"TITLE={title}{part_text}")
    if not series:
        properties['ALBUM'] = title
        #print(f"ALBUM={title}")
    else:
        properties['ALBUM'] = f'{series} Book {book:02} - {title}'
        #print(f"ALBUM={series} Book {book:02} - {title}")
    #print(f"ARTIST={oxford_command_join(authors)}")
    #print(f"COMMENT=Read by {oxford_command_join(narrators)}")
    lc_author = slugify(authors[0].lower().replace(" ","_"))
    lc_title = slugify(title.lower().replace(" ","_").replace(".",""))
    if not series:
        properties['OUT'] = f'{lc_author}-{lc_title}{lc_part_text}.m4b'
        #print(f"OUT={lc_author}-{lc_title}{lc_part_text}.m4b")
    else:
        lc_series = slugify(series.lower().replace(" ","_"))
        properties['OUT'] = f'{lc_author}-{lc_series}_{book:02}-{lc_title}{lc_part_text}.m4b'
        #print(f"OUT={lc_author}-{lc_series}_book_{book:02}-{lc_title}{lc_part_text}.m4b")
    info = import_info_txt()
    info['YEAR'] = hardback_year_google(author=authors[0], title=title)
    if not info:
        for k,v in properties.items():
            print(f'{k}={v}')
    else:
        for k,v in properties.items():
            info[k.strip()] = v.strip()
        if not orig_info_exists():
            backup_info_text()
            logging.warning("Backed up info.txt to info.txt.orig")
        with open("info.txt", "w") as f:
            for k,v in info.items():
                f.write(f'{k}={v}\n')
            logging.info("Wrote to info.txt")
        with open("description.txt", "w") as f:
            f.write(str(description))
            logging.info("Wrote to description.txt")

if __name__ == '__main__':
    main()
